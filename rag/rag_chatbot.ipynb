{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30426d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import import_ipynb\n",
    "from openai import OpenAI\n",
    "from build_vector_db import get_embedding\n",
    "from chromadb import Client\n",
    "import chromadb \n",
    "from chromadb.config import Settings \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "dbclient = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = dbclient.get_or_create_collection(\"rag_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79530fde",
   "metadata": {},
   "source": [
    " query를 임베딩해 chroma에서 가장 유사도가 높은 top-k개의 문서 가져오는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query를 임베딩해 chroma에서 가장 유사도가 높은 top-k개의 문서 가져오는 함수 \n",
    "def retrieve(query, top_k=3):\n",
    "    query_embedding = get_embedding(query) # qeury에 대한 임베딩 생성\n",
    "    # collection.query 함수로 저장된 문서 임베딩들 중에서\n",
    "    # query임베딩과 가장 유사한 항목들 검색 \n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    ) \n",
    "    # 이때 results에는 해당 query 임베딩에 대한 텍스트, 메타데이터, id등이 전부 포함됨 \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d197d0",
   "metadata": {},
   "source": [
    "1) query에 대해 벡터 DB에서 top_k개 문서 retrieval\n",
    "2) 그 문서들을 context로 묶어 GPT에 prompt\n",
    "3) 최종 답변 반환\n",
    "하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "흐름 \n",
    "1) query에 대해 벡터 DB에서 top_k개 문서 retrieval\n",
    "2) 그 문서들을 context로 묶어 GPT에 prompt\n",
    "3) 최종 답변 반환 \n",
    "하는 함수 \n",
    "\"\"\"\n",
    "def generate_answer_with_context(query, top_k=3):\n",
    "\n",
    "    results = retrieve(query, top_k) # retrieve 함수로 결과 얻기\n",
    "    # top_k에 대한 documents와 metadatas 리스트로 추출\n",
    "    found_docs = results[\"documents\"][0] \n",
    "    found_metadatas = results[\"metadatas\"][0]\n",
    "\n",
    "    # context 구성 (검색된 문서들을 하나의 문맥으로 결합)\n",
    "    context_texts = []\n",
    "    # zip을 이용해 두 리스트의 같은 인덱스에 있는 값들을 한 쌍으로 묶음\n",
    "    for doc_text, meta in zip(found_docs, found_metadatas): \n",
    "        context_texts.append(f\"<<filename: {meta['filename']}>>\\n{doc_text}\")\n",
    "    # context_texts 리스트에 있는 모든 문자열이 \\n\\n으로 이어 붙여짐\n",
    "    context_str = \"\\n\\n\".join(context_texts)\n",
    "\n",
    "    # 프롬프트 작성\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 주어진 문서 정보를 바탕으로 사용자 질문에 답변하는\n",
    "    지능형 어시스턴트입니다. 다음 원칙을 엄격히 지키세요:\n",
    "\n",
    "    1. 반드시 제공된 문서 내용에 근거해서만 답변을 작성하세요.\n",
    "    2. 문서에 언급되지 않은 내용이라면, 함부로 추측하거나 만들어내지 마세요. \n",
    "    - 예를 들어, 문서에 특정 인물, 사건이 전혀 언급되지 않았다면 \n",
    "    “관련 문서를 찾지 못했습니다” 또는 “정보가 없습니다”라고 답변하세요.\n",
    "    3. 사실 관계를 명확히 기술하고, 불확실한 부분은 “정확한 정보를 찾지 못했습니다”라고 말하세요.\n",
    "    4. 지나치게 장황하지 않게, 간결하고 알기 쉽게 설명하세요.\n",
    "    5. 사용자가 질문을 한국어로 한다면, 한국어로 답변하고, \n",
    "    다른 언어로 질문한다면 해당 언어로 답변하도록 노력하세요.\n",
    "    6. 문서 출처나 연도가 중요하다면, 가능한 정확하게 전달하세요.\n",
    "\n",
    "    당신은 전문적인 지식을 갖춘 듯 정확하고, 동시에 친절하고 이해하기 쉬운 어투를 구사합니다. \n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt =f\"\"\"아래는 검색된 문서들의 내용입니다:\n",
    "    {context_str}\n",
    "    질문: {query}\"\"\"\n",
    "    \n",
    "\t\t# context_str과 query를 같이 프롬프트에 넣어버림\n",
    "    \n",
    "    # ChatGPT 호출 \n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages = [{\"role\":\"system\", \"content\": system_prompt},\n",
    "        {\"role\":\"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b2080",
   "metadata": {},
   "source": [
    " RAG 없이 응답하는 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f730ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 없이 응답하는 함수 \n",
    "def generate_answer_without_context(query):\n",
    "     api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "     client = OpenAI(api_key=api_key)\n",
    "\n",
    "     response = client.chat.completions.create(\n",
    "         model = \"gpt-4o-mini\",\n",
    "         messages=[{\"role\":\"system\", \"content\":\"you are helpful assistant\"},\n",
    "                   {\"role\":\"user\", \"content\": query}]\n",
    "     )\n",
    "\n",
    "     answer = response.choices[0].message.content \n",
    "     return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943149b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_query = input(\"질문을 입력하세요(종료: quit): \")\n",
    "        if user_query.lower() == \"quit\":\n",
    "            break \n",
    "        answer = generate_answer_with_context(user_query, top_k=3)\n",
    "        # answer = generate_answer_without_context(user_query)\n",
    "        print(\"===답변===\")\n",
    "        print(answer)\n",
    "        print(\"==========\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import tkinter.ttk as ttk\n",
    "def reset_status():\n",
    "    label_status.config(text=\"\", foreground=\"black\")\n",
    "\n",
    "def process_query():\n",
    "    query = text_input.get(\"1.0\", END).strip()\n",
    "    print(f\"User Query: {query}\")\n",
    "    if query:\n",
    "        label_status.config(text=\"질문 처리중...\", foreground=\"blue\")\n",
    "        answer = generate_answer_with_context(query)\n",
    "        print(f\"Answer: {answer}\")\n",
    "        label_status.config(text=\"처리 완료 ✅\", foreground=\"green\")\n",
    "        root.after(2000, reset_status)\n",
    "        text_input.delete(\"1.0\", \"end-1c\")          # 입력창 비우기\n",
    "        text_output.config(state=\"normal\")\n",
    "        text_output.delete(\"1.0\", END)\n",
    "        text_output.insert(END, answer)\n",
    "        text_output.config(state=\"disabled\")   # 출력창 편집 불가\n",
    "    else:\n",
    "        label_status.config(text=\"질문을 입력해주세요.\", foreground=\"red\")\n",
    "\n",
    "root = Tk()\n",
    "root.title('RAG 챗봇')\n",
    "root.geometry('500x700')\n",
    "root.resizable(False, False)\n",
    "# 전체 배경 연보라\n",
    "root.configure(bg=\"lavender\")\n",
    "# ====== 상단 이미지 영역 ======\n",
    "img = PhotoImage(file=\"source/hateslop.png\")\n",
    "label_img = Label(root, image=img, bg=\"white\")\n",
    "label_img.pack(pady=10)\n",
    "\n",
    "# ====== 입력 영역 ======\n",
    "frame_input = Frame(root, padx=10, pady=10)\n",
    "frame_input.pack(fill=\"x\")\n",
    "\n",
    "label_input = ttk.Label(frame_input, text=\"질문 입력\", font=(\"맑은 고딕\", 12, \"bold\"))\n",
    "label_input.pack(anchor=\"w\")\n",
    "\n",
    "text_input = Text(frame_input, height=6, font=(\"맑은 고딕\", 11))\n",
    "text_input.pack(pady=5)\n",
    "\n",
    "btn = ttk.Button(frame_input, text=\"전송\", command=process_query)\n",
    "btn.pack(pady=5)\n",
    "\n",
    "label_status = ttk.Label(frame_input, text=\"\", font=(\"맑은 고딕\", 10))\n",
    "label_status.pack(anchor=\"w\", pady=5)\n",
    "\n",
    "separator = ttk.Separator(root, orient=\"horizontal\")\n",
    "separator.pack(fill=\"x\", padx=10, pady=10)\n",
    "# ====== 출력 영역 ======\n",
    "frame_output = Frame(root, padx=10, pady=10)\n",
    "frame_output.pack(fill=\"both\", expand=True)\n",
    "\n",
    "label_output = ttk.Label(frame_output, text=\"답변\", font=(\"맑은 고딕\", 12, \"bold\"))\n",
    "label_output.pack(anchor=\"w\")\n",
    "\n",
    "text_output = Text(frame_output, wrap=\"word\", font=(\"맑은 고딕\", 11), state=\"disabled\", height=20, bg=\"#f9f9f9\")\n",
    "text_output.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "scrollbar = ttk.Scrollbar(frame_output, command=text_output.yview)\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "text_output.config(yscrollcommand=scrollbar.set)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hateslop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
