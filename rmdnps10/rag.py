# # ì‹¤ì œë¡œ ì›¹ì—ì„œ í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ ëª¨ì•„ì„œ ë³¸ì¸ì´ ì§ì ‘ FAQë¥¼ ìƒì„±í•´ë³´ê¸°
# # í•„ìˆ˜ì ìœ¼ë¡œ ì‚¬ìš©í•  ê¸°ëŠ¥
# # ì›¹ í¬ë¡¤ë§ìœ¼ë¡œ ì›ì²œ ë°ì´í„° í™•ë³´í•˜ê¸°
# # Embe    df.to_csv(CSV_PATH, index=Fals# CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
# # ììœ  ì£¼ì œì´ë©° ì‹¤ìŠµë•Œ êµ¬í˜„í•œ ë‚´ìš©ì„ ì¶©ë¶„íˆ í™œìš© ë° ë³µìŠµí•´ë³´ê¸°

# # 1. ì›¹ í¬ë¡¤ë§ìœ¼ë¡œ ì›ì²œ ë°ì´í„° í™•ë³´í•˜ê¸° by using Selenium & BeautifulSoup
# from selenium import webdriver
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException
# from bs4 import BeautifulSoup
# import pandas as pd
# import time

# def get_dynamic_page_source(url, timeout=10):
#     """Seleniumì„ ì‚¬ìš©í•˜ì—¬ ë™ì  í˜ì´ì§€ ì†ŒìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
#     driver = None
#     try:
#         # Headless ëª¨ë“œë¡œ ì‹¤í–‰í•˜ì—¬ ë¸Œë¼ìš°ì € ì°½ì„ ë„ìš°ì§€ ì•ŠìŒ
#         options = webdriver.ChromeOptions()
#         options.add_argument("--headless")
#         options.add_argument("--no-sandbox")
#         options.add_argument("--disable-dev-shm-usage")
#         options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")

#         driver = webdriver.Chrome(options=options)
#         driver.get(url)
        
#         wait = WebDriverWait(driver, timeout)
#         wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'ul[class*="news_list"]')))
        
#         print("âœ… ë™ì  ì½˜í…ì¸  ë¡œë”© ì™„ë£Œ.")
#         return driver.page_source

#     except TimeoutException:
#         print("âŒ í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼: ë‰´ìŠ¤ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#         return None
#     except Exception as e:
#         print(f"âŒ Selenium ì˜¤ë¥˜ ë°œìƒ: {e}")
#         return None
#     finally:
#         if driver:
#             driver.quit()
#             print("âœ… Selenium ë“œë¼ì´ë²„ ì¢…ë£Œ.")

# # ì‹¤ì œ í¬ë¡¤ë§í•  URL
# url = "https://m.sports.naver.com/kbaseball/news?sectionId=kbo&team=SS&sort=latest&date=20250926&isPhoto=Y"
# page_source = get_dynamic_page_source(url)

# if page_source is None:
#     print("âŒ ì›¹í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨")
#     exit(1)

# soup = BeautifulSoup(page_source, 'html.parser')  
# # CSS ì„ íƒì ìˆ˜ì • (ë™ì  í´ë˜ìŠ¤ ì´ë¦„ ëŒ€ì‘)
# articles = soup.select('.NewsItem_info_area__Dj4oW')

# if not articles:
#     print("âŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSS ì„ íƒìë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
#     exit(1)

# print(f"âœ… {len(articles)}ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")

# data = []
# successful_crawls = 0

# for i, article in enumerate(articles, 1):
#     try:
#         # articleì˜ ìì‹ em ìš”ì†Œ ì„ íƒ 
#         title_element = article.select_one('em')
#         summary_element = article.select_one('p')  
        
#         if title_element and summary_element:
#             title = title_element.get_text(strip=True)
#             summary = summary_element.get_text(strip=True)
            
#             # ë°ì´í„° ê²€ì¦
#             if title and summary and len(title) > 3 and len(summary) > 10:
#                 data.append({'title': title, 'summary': summary})
#                 successful_crawls += 1
#             else:
#                 print(f"âš ï¸  ê¸°ì‚¬ {i}: ë°ì´í„°ê°€ ë¶ˆì™„ì „í•¨ (ì œëª©: {len(title)}ì, ìš”ì•½: {len(summary)}ì)")
#         else:
#             print(f"âš ï¸  ê¸°ì‚¬ {i}: ì œëª© ë˜ëŠ” ìš”ì•½ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
#     except Exception as e:
#         print(f"âš ï¸  ê¸°ì‚¬ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# # ë°ì´í„° ê²€ì¦ ë° ì €ì¥
# if data:
#     df = pd.DataFrame(data)
#     df.to_csv('sports_news.csv', index=False, encoding='utf-8-sig')  # í•œê¸€ ì¸ì½”ë”© ì¶”ê°€
#     print(f"âœ… ì´ {successful_crawls}ê°œì˜ ê¸°ì‚¬ê°€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
#     print(f"âœ… CSV íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: sports_news.csv")
# else:
#     print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í¬ë¡¤ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
#     exit(1) 


# 2. Embedding ë° Chroma DB ì‚¬ìš©ë²• ì‹¤ìŠµ
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter  
from langchain_community.document_loaders import CSVLoader
from langchain.chains import RetrievalQA
from langchain_community.llms import OpenAI
from dotenv import load_dotenv
import os

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CSV_PATH = os.path.join(BASE_DIR, 'sports_news.csv')
DB_PATH = os.path.join(BASE_DIR, 'chroma_db')

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ (ë³´ì•ˆ ê°•í™”)
load_dotenv()
print(os.getenv("OPENAI_API_KEY"))
      
if not os.getenv("OPENAI_API_KEY"):
    print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    print("ğŸ’¡ .env íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ ì¶”ê°€í•˜ì„¸ìš”: OPENAI_API_KEY=your_api_key_here")
    os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
if not os.path.exists(CSV_PATH):
    print("âŒ sports_news.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

try:
    print("ğŸ“š CSV íŒŒì¼ì„ ë¡œë”© ì¤‘...")
    loader = CSVLoader(file_path=CSV_PATH, encoding='utf-8')
    documents = loader.load()
    
    if not documents:
        print("âŒ ë¡œë”©ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)
        
    print(f"âœ… {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë”©í–ˆìŠµë‹ˆë‹¤.")
    
    # í•œêµ­ì–´ì— ìµœì í™”ëœ í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=400,  # í•œêµ­ì–´ì— ì í•©í•œ ì‚¬ì´ì¦ˆ
        chunk_overlap=40,
        separators=["\n\n", "\n", ".", "!", "?", " ", ""]
    )
    
    print("ğŸ“ ë¬¸ì„œë¥¼ ë¶„í•  ì¤‘...")
    texts = text_splitter.split_documents(documents)
    print(f"âœ… {len(texts)}ê°œì˜ í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")
    
    print("ğŸ¤– ì„ë² ë”© ìƒì„± ì¤‘...")
    embeddings = OpenAIEmbeddings()
    
    # Chroma DBì— ì €ì¥
    print("ğŸ—„ï¸ Chroma DBì— ì €ì¥ ì¤‘...")
    vectordb = Chroma.from_documents(
        documents=texts, 
        embedding=embeddings, 
        persist_directory=DB_PATH  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
    )
    vectordb.persist()
    print("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ê²€ìƒ‰ ì‹œìŠ¤í…œ ì„¤ì •
    retriever = vectordb.as_retriever(
        search_type="similarity", 
        search_kwargs={"k": 3}
    )
    
    # LLM ë° QA ì²´ì¸ ì„¤ì •
    llm = OpenAI(temperature=0)
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm, 
        chain_type="stuff", 
        retriever=retriever,
        return_source_documents=True  # ì†ŒìŠ¤ ë¬¸ì„œë„ ë°˜í™˜
    )
    print("âœ… QA ì²´ì¸ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"âŒ RAG ì‹œìŠ¤í…œ êµ¬ì¶• ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit(1)


def test_qa_system():
    """QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    test_queries = [
        "ìµœê·¼ ì•¼êµ¬ ê²½ê¸° ì†Œì‹ ì•Œë ¤ì¤˜",
        "ì‚¼ì„± ë¼ì´ì˜¨ì¦ˆ ë””ì•„ì¦ˆëŠ” í™ˆëŸ° ê°œìˆ˜ëŠ”?",
        "ì‚¼ì„± ë¼ì´ì˜¨ì¦ˆ ë””ì•„ì¦ˆì˜ íƒ€ì  ê°œìˆ˜ëŠ”?"
    ]
    
    print("\n" + "="*50)
    print("ğŸ¤– QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*50)
    
    for i, query in enumerate(test_queries, 1):
        try:
            print(f"\nğŸ“ ì§ˆë¬¸ {i}: {query}")
            print("-" * 30)
            
            # ì§ˆì˜ì‘ë‹µ ì‹¤í–‰
            result = qa_chain({"query": query})
            
            print(f"ğŸ¤– ë‹µë³€: {result['result']}")
            
            # ì†ŒìŠ¤ ë¬¸ì„œ ì •ë³´ ì¶œë ¥
            if 'source_documents' in result:
                print(f"\nğŸ“š ì°¸ì¡° ë¬¸ì„œ {len(result['source_documents'])}ê°œ:")
                for j, doc in enumerate(result['source_documents'], 1):
                    content = doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content
                    print(f"  {j}. {content}")
            
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        print("\n" + "-" * 50)

# QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if 'qa_chain' in locals():
    test_qa_system()
else:
    print("âŒ QA ì²´ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")